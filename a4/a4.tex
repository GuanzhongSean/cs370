\documentclass{article}
\usepackage[a4paper,margin=1in]{geometry}
\usepackage{amsmath,amsfonts,amssymb,graphicx}
\title{\textbf{CS 370 Winter 2025: Assignment 4}}
\author{Jiaze Xiao \\ 20933691}
\date{\today}
\setlength{\parindent}{0pt}
\begin{document}

\maketitle

\section*{Question 1}
\subsection*{(a)}
Compare the magnitudes in the first column:
$$
    |1| = 1, \quad \Bigl|\tfrac12\Bigr| = 0.5, \quad \Bigl|\tfrac13\Bigr| \approx 0.333.
$$
The largest is $1$ (in row~1), so no row-swap is needed at this step. We got multipliers
$$
    \ell_{21} = \tfrac12,
    \quad
    \ell_{31} = \tfrac13.
$$
Then for row~2 and row~3, we do:
$$
    \begin{aligned}
        R_2 & \leftarrow R_2 - \tfrac12R_1, \\
        R_3 & \leftarrow R_3 - \tfrac13R_1.
    \end{aligned}
$$
After these operations, the matrix becomes
$$
    \begin{bmatrix}
        1 & 7         & 3         \\
        0 & -\tfrac54 & -\tfrac74 \\
        0 & 5         & -1
    \end{bmatrix}.
$$
Since $|-\tfrac54| \approx 1.25 < |5| = 5$, we swap row~2 and row~3. This introduces one permutation in $P$. After the swap, we have
$$
    \begin{bmatrix}
        1 & 7         & 3         \\
        0 & 5         & -1        \\
        0 & -\tfrac54 & -\tfrac74
    \end{bmatrix}\quad
    \text{and}\quad
    \ell_{21} = \tfrac13,
    \quad
    \ell_{31} = \tfrac12.
$$
Now eliminate below the pivot $5$ in row~2 using multiplier
$$
    \ell_{32} = \frac{-\tfrac54}{5} = -\tfrac14.
$$
Then for row~3, we do:
$$
    R_3 \leftarrow R_3 -(-\tfrac14)R_2.
$$
Thus we arrive at
$$
    U =
    \begin{bmatrix}
        1 & 7 & 3  \\
        0 & 5 & -1 \\
        0 & 0 & -2
    \end{bmatrix}.
$$
Therefore, the final factorization is
$$
    \boxed{
        P =
        \begin{bmatrix}
            1 & 0 & 0 \\
            0 & 0 & 1 \\
            0 & 1 & 0
        \end{bmatrix},
        \quad
        L =
        \begin{bmatrix}
            1        & 0         & 0 \\
            \tfrac13 & 1         & 0 \\
            \tfrac12 & -\tfrac14 & 1
        \end{bmatrix},
        \quad
        U =
        \begin{bmatrix}
            1 & 7 & 3  \\
            0 & 5 & -1 \\
            0 & 0 & -2
        \end{bmatrix}
    }.
$$

\newpage
\subsection*{(b)}
Let $z = Ux$. Then
$$
    Lz = Pb \quad\text{and}\quad Ux = z.
$$

\paragraph{1. Compute $Pb$.}
$$
    Pb
    =
    \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 0 & 1 \\
        0 & 1 & 0
    \end{bmatrix}
    \begin{bmatrix}0\\4\\8\end{bmatrix}
    =
    \begin{bmatrix}0\\8\\4\end{bmatrix}.
$$

\paragraph{2. Solve $Lz = Pb$.}
$$
    L
    =
    \begin{bmatrix}
        1        & 0         & 0 \\
        \tfrac13 & 1         & 0 \\
        \tfrac12 & -\tfrac14 & 1
    \end{bmatrix},
    \quad
    z = \begin{bmatrix}z_1\\z_2\\z_3\end{bmatrix},
    \quad
    Pb = \begin{bmatrix}0\\8\\4\end{bmatrix}.
$$
Forward solve:
$$
    \begin{aligned}
         & \text{(Row 1)}\quad 1z_1 = 0 \Longrightarrow z_1=0,              \\
         & \text{(Row 2)}\quad \tfrac13z_1 + z_2 = 8 \Longrightarrow z_2=8, \\
         & \text{(Row 3)}\quad \tfrac12z_1 - \tfrac14z_2 + z_3 = 4
        \Longrightarrow
        -\tfrac14\cdot 8 + z_3 = 4
        \Longrightarrow
        z_3=6.
    \end{aligned}
$$
Hence
$$
    z
    =
    \begin{bmatrix}
        0 \\
        8 \\
        6
    \end{bmatrix}.
$$

\paragraph{3. Solve $Ux = z$.}
$$
    U
    =
    \begin{bmatrix}
        1 & 7 & 3  \\
        0 & 5 & -1 \\
        0 & 0 & -2
    \end{bmatrix},
    \quad
    x
    =
    \begin{bmatrix}x_1\\x_2\\x_3\end{bmatrix},
    \quad
    z
    =
    \begin{bmatrix}0\\8\\6\end{bmatrix}.
$$
Backward solve:
$$
    \begin{aligned}
         & \text{(Row 3)}\quad -2x_3 = 6 \Longrightarrow x_3=-3, \\
         & \text{(Row 2)}\quad 5x_2 - x_3 = 8
        \Longrightarrow
        5x_2 + 3=8
        \Longrightarrow
        x_2=1,                                                   \\
         & \text{(Row 1)}\quad x_1 + 7x_2 + 3x_3=0
        \Longrightarrow
        x_1 +7(1)+3(-3)=0
        \Longrightarrow
        x_1 +7-9=0
        \Longrightarrow
        x_1=2.
    \end{aligned}
$$
Therefore,
$$
    \boxed{
        x
        =
        \begin{bmatrix}
            2 \\
            1 \\
            -3
        \end{bmatrix}
    }.
$$

\newpage
\section*{Question 2}
\subsection*{(a)}
From $PA = LU$, we can write $A = P^T LU$ since $P$ is always orthogonal (i.e. $PP^T=I\Longrightarrow P^T=P^{-1}$). Taking the transpose, we get
$$
    A^T = (P^T LU)^T = U^TL^TP.
$$
Thus the system
$$
    A^T x = v
$$
becomes
$$
    U^T  L^T  P  x = v.
$$
Let $y = Px$, then
$$
    U^T  L^T  y = v.
$$
We can solve this in two triangular solves:
\begin{enumerate}
    \item First solve
          $$
              L^Tz = v,
          $$
          which is an \emph{upper triangular} system (since $L$ is lower triangular, $L^T$ is upper triangular). Call the result $z$.
    \item Next solve
          $$
              U^Ty = z,
          $$
          which is again a triangular system (since $U$ is upper triangular, $U^T$ is lower triangular, but the procedure is still a standard triangular solve). Call the result $y$.
    \item Finally, recover $x$ from $y$ using
          $$
              x = P^T  y.
          $$
\end{enumerate}
The permutation $P^T$ simply reorders the components of $y$ to form $x$, and by the problem statement, we consider permutations (and transpositions) to require 0 FLOPs, since they can be done via indexing.

\subsection*{(b)}
Our solve proceeds by two triangular solves:
\begin{itemize}
    \item A triangular solve (e.g.\ $L^T z = v$) typically requires on the order of $\tfrac12n(n+1)$ multiplications plus the same number of additions, which is $O(n^2)$ overall.
    \item The second triangular solve $U^T y = z$ is likewise $O(n^2)$.
\end{itemize}

Hence, in total, the algorithm uses roughly
$$
    \boxed{O(n^2) \text{ FLOPs}}
$$
for the pair of triangular solves.

\newpage
\section*{Question 3}
\subsection*{(a)}
One possible procedure is described as follows:

\begin{enumerate}
    \item Compute $V = bc^T$.  This is an $n\times n$ outer product and costs $n^2$ FLOPs.
    \item Factor $A^T = LU$. A standard $LU$ factorization of an $n \times n$ matrix takes $\tfrac{2}{3}n^3 + O(n^2)$ FLOPs.
    \item Solving each row of $W$ as a seperate linear system, so need to do $n$ pairs of forward and backward solves, which costs $2n^2+O(n)$ FLOPs for each pair $\Longrightarrow 2n^3+O(n^2)$ in total.
\end{enumerate}
Putting these together,
$$
    \boxed{
    \underbrace{n^2}_{\text{compute }V}
    +
    \underbrace{\tfrac{2}{3}n^3+O(n^2)}_{\text{factor }A^T}
    +
    \underbrace{2n^3+O(n^2)}_{\substack{\text{forward/back}\\\text{solves per row}}}
    =
    \frac{8}{3}n^3
    +O(n^2)
    }.
$$
Hence the overall flop count is $\frac{8}{3}n^3 + O(n^2)$.

\subsection*{(b)}
We can reduce the cost significantly by reordering how we compute $W$.
Observe that
$$
    W
    =
    bc^TA^{-1}
    =
    b
    \bigl(c^TA^{-1}\bigr).
$$
If we define a row vector
$$
    w^T = c^TA^{-1}
    \quad\Longrightarrow\quad
    W = bw^T,
$$
so that $W$ is the outer product of $b$ and $w^T$.
Thus we only need to compute the single row vector $w^T$.
But $w^T = c^TA^{-1}$ is equivalent to $w^T A = c^T$, or
$$
    A^T w = c,
$$
which becomes a normal linear system. We can simply solve it using LU factorization. Thus, we have reduced the leading cost from $\tfrac{8}{3}n^3$ in part~(a) to $\tfrac{2}{3}n^3+O(n^2)$ (the cost of LU factorization).

\newpage
\section*{Question 4}
Here is the Markov Chain Matrix for the given graph:
$$
    P
    =
    \begin{bmatrix}
        0        & 0        & 0        & 0        & 1 & \tfrac13 \\[3pt]
        \tfrac12 & 0        & \tfrac12 & \tfrac12 & 0 & 0        \\[3pt]
        \tfrac12 & \tfrac13 & 0        & 0        & 0 & 0        \\[3pt]
        0        & \tfrac13 & 0        & 0        & 0 & \tfrac13 \\[3pt]
        0        & \tfrac13 & \tfrac12 & \tfrac12 & 0 & \tfrac13 \\[3pt]
        0        & 0        & 0        & 0        & 0 & 0
    \end{bmatrix}.
$$
Since $\alpha=1/2$, each page~$j$ contributes a weight of $\tfrac12 \cdot \tfrac{1}{d_j}$ to any $i$ that it links to, plus the random-jump contribution of $\tfrac12 \cdot \tfrac{1}{6}=\tfrac{1}{12}$ to every page~$i$. We obtain the complete $6\times 6$ matrix:
$$
    M
    =
    \begin{bmatrix}
        \frac{1}{12} & \frac{1}{12} & \frac{1}{12} & \frac{1}{12} & \frac{7}{12} & \frac{1}{4}  \\[5pt]
        \frac{1}{3}  & \frac{1}{12} & \frac{1}{3}  & \frac{1}{3}  & \frac{1}{12} & \frac{1}{12} \\[5pt]
        \frac{1}{3}  & \frac{1}{4}  & \frac{1}{12} & \frac{1}{12} & \frac{1}{12} & \frac{1}{12} \\[5pt]
        \frac{1}{12} & \frac{1}{4}  & \frac{1}{12} & \frac{1}{12} & \frac{1}{12} & \frac{1}{4}  \\[5pt]
        \frac{1}{12} & \frac{1}{4}  & \frac{1}{3}  & \frac{1}{3}  & \frac{1}{12} & \frac{1}{4}  \\[5pt]
        \frac{1}{12} & \frac{1}{12} & \frac{1}{12} & \frac{1}{12} & \frac{1}{12} & \frac{1}{12}
    \end{bmatrix}.
$$
We assume the initial probability vector is
$$
    p^{(0)}
    =
    \begin{bmatrix}
        \tfrac14 \\[3pt]
        \tfrac14 \\[3pt]
        0        \\[3pt]
        \tfrac14 \\[3pt]
        0        \\[3pt]
        \tfrac14
    \end{bmatrix},
$$
meaning the surfer starts on pages 1, 2, 4, and~6 with probability $1/4$ each, and has zero probability of being on pages~3 or~5.

The probability vector after one step is given by
$$
    p^{(1)} = M p^{(0)}.
$$
Because $p^{(0)}$ has zeros in the 3rd and 5th entries, we only need the matrix columns 1, 2, 4, and~6 (each scaled by $1/4$).  Define
$$
    \text{colSum} = M(\cdot,1) + M(\cdot,2) + M(\cdot,4) + M(\cdot,6).
$$
Then
$$
    p^{(1)}
    =
    \frac{1}{4}\text{colSum}.
$$
Thus, after one step of surfing (with $\alpha=1/2$), the new probability of being on each of the 6 pages is exactly
$$
    \boxed{
        p^{(1)}
        =
        \begin{bmatrix}
            \tfrac{1}{8}   \\[3pt]
            \tfrac{5}{24}  \\[3pt]
            \tfrac{3}{16}  \\[3pt]
            \tfrac{1}{6}   \\[3pt]
            \tfrac{11}{48} \\[3pt]
            \tfrac{1}{12}
        \end{bmatrix}.
    }
$$

\end{document}
